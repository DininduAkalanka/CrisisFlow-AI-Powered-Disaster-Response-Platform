"""
Geospatial Clustering Service - PostGIS Native Implementation
Uses ST_ClusterDBSCAN directly in PostgreSQL for high-performance spatial clustering
"""
from sqlalchemy.orm import Session
from sqlalchemy import text
from typing import Dict, List
from app.core.config import settings


class GeospatialClusteringService:
    """
    Production-Grade Geospatial Clustering using PostGIS
    
    Features:
    - Native PostGIS ST_ClusterDBSCAN for spatial clustering
    - Efficient server-side processing (no Python scikit-learn)
    - Configurable clustering parameters (eps, minpoints)
    - Real-time cluster updates
    """
    
    def __init__(self):
        # Clustering parameters
        self.eps = 0.005  # ~500 meters in decimal degrees
        self.minpoints = 3  # Minimum incidents to form a cluster
    
    async def update_incident_clusters(self, db: Session) -> Dict[str, any]:
        """
        Execute PostGIS ST_ClusterDBSCAN to group nearby incidents
        
        Args:
            db: SQLAlchemy database session
            
        Returns:
            Dict with clustering statistics
        """
        # PostGIS disabled - return empty clustering result
        return {
            "status": "success",
            "total_clusters": 0,
            "clusters": [],
            "unclustered_count": 0,
            "largest_cluster_size": 0,
            "parameters": {
                "eps": self.eps,
                "minpoints": self.minpoints
            },
            "note": "PostGIS clustering disabled"
        }
        
        # Original PostGIS code (disabled):
        """
        try:
            # ===== STEP 1: Execute PostGIS ST_ClusterDBSCAN =====
            query = text(\"\"\"
                WITH clustered AS (
                    SELECT 
                        id,
                        title,
                        latitude,
                        longitude,
                        ST_ClusterDBSCAN(location, eps := :eps, minpoints := :minpoints) 
                            OVER () AS cluster_id
                    FROM incidents
                    WHERE status != 'resolved'
                        AND created_at >= NOW() - INTERVAL '24 hours'
                )
                UPDATE incidents
                SET cluster_id = clustered.cluster_id
                FROM clustered
                WHERE incidents.id = clustered.id
                RETURNING incidents.cluster_id;
            \"\"\")
            
            result = db.execute(
                query,
                {
                    "eps": self.eps,
                    "minpoints": self.minpoints
                }
            )
            db.commit()
            
            # ===== STEP 2: Collect clustering statistics =====
            stats_query = text(\"\"\"
                SELECT 
                    cluster_id,
                    COUNT(*) as incident_count,
                    AVG(latitude) as center_lat,
                    AVG(longitude) as center_lon,
                    ARRAY_AGG(id) as incident_ids
                FROM incidents
                WHERE cluster_id IS NOT NULL
                    AND status != 'resolved'
                    AND created_at >= NOW() - INTERVAL '24 hours'
                GROUP BY cluster_id
                ORDER BY incident_count DESC;
            \"\"\")
            
            clusters_result = db.execute(stats_query).fetchall()
            
            clusters = []
            for row in clusters_result:
                clusters.append({
                    "cluster_id": row[0],
                    "incident_count": row[1],
                    "center": {
                        "latitude": float(row[2]),
                        "longitude": float(row[3])
                    },
                    "incident_ids": row[4]
                })
            
            # Count unclustered incidents
            unclustered_query = text(\"\"\"
                SELECT COUNT(*) 
                FROM incidents 
                WHERE cluster_id IS NULL 
                    AND status != 'resolved'
                    AND created_at >= NOW() - INTERVAL '24 hours';
            \"\"\")
            unclustered_count = db.execute(unclustered_query).scalar()
            
            return {
                "status": "success",
                "total_clusters": len(clusters),
                "clusters": clusters,
                "unclustered_count": unclustered_count,
                "largest_cluster_size": clusters[0]["incident_count"] if clusters else 0,
                "parameters": {
                    "eps": self.eps,
                    "minpoints": self.minpoints
                }
            }
            
        except Exception as e:
            print(f"âœ— Error in update_incident_clusters: {str(e)}")
            import traceback
            traceback.print_exc()
            db.rollback()
            return {
                "status": "error",
                "error": str(e),
                "total_clusters": 0,
                "clusters": [],
                "unclustered_count": 0
            }
        """


# Singleton instance
_clustering_service = None


def get_clustering_service() -> GeospatialClusteringService:
    """Get singleton instance of GeospatialClusteringService"""
    global _clustering_service
    if _clustering_service is None:
        _clustering_service = GeospatialClusteringService()
    return _clustering_service
